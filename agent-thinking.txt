# Agentic Workflow with GRPO Training: Detailed Implementation Plan

# === Agentic Workflow Diagrams ===

## High-Level Agentic Workflow (Mermaid)

```mermaid
flowchart TD
    subgraph Message_Bus[Message Bus (RabbitMQ)]
        direction TB
        TaskQ[Task Queue]
        ResponseQ[Response Queue]
        RewardQ[Reward Queue]
    end

    UserInput[User/Input Source] -->|Task| TaskQ
    TaskQ -->|Task| SmallModelAgent[Small Model Agent]
    SmallModelAgent -->|Response| ResponseQ
    ResponseQ -->|Response| ScoringAgent[Scoring Agent (Big Model)]
    ScoringAgent -->|Reward| RewardQ
    RewardQ -->|Reward| SmallModelAgent
    SmallModelAgent -->|Log| LogFile[Logs/agent_interactions.jsonl]
    ScoringAgent -->|Log| LogFile
    Orchestrator[Orchestrator/Controller] -- Coordinates --> TaskQ
    Orchestrator -- Monitors --> ResponseQ
    Orchestrator -- Monitors --> RewardQ
    Orchestrator -- Logs --> LogFile
    LogFile -->|Training Data| Trainer[Trainer Service]
    Trainer -->|New Adapter| AdapterRegistry[Adapter Registry]
    AdapterRegistry --> Orchestrator
```

---

## Detailed Agent Interaction & Scoring (Mermaid)

```mermaid
sequenceDiagram
    participant User
    participant Orchestrator
    participant SmallModelAgent
    participant MessageBus
    participant ScoringAgent
    participant Trainer

    User->>Orchestrator: Submit Task
    Orchestrator->>MessageBus: Publish Task (Task Queue)
    MessageBus->>SmallModelAgent: Deliver Task
    SmallModelAgent->>MessageBus: Publish Response (Response Queue)
    MessageBus->>ScoringAgent: Deliver Response
    ScoringAgent->>MessageBus: Publish Reward (Reward Queue)
    MessageBus->>SmallModelAgent: Deliver Reward
    SmallModelAgent->>Orchestrator: Log Interaction
    ScoringAgent->>Orchestrator: Log Score
    Orchestrator->>Trainer: Provide Logs for Training
    Trainer->>Orchestrator: Notify New Adapter Version
```

These diagrams visually represent the agentic workflow and message flow described in this implementation plan. They can be used in documentation and as a reference for implementation.

## 1. Problem Statement
Design a scalable agentic workflow where multiple agents (MCP servers) communicate via message queues. Each response from a small model agent is scored by a more intelligent big model agent, and the small model is trained using GRPO (Generalized Reinforce Policy Optimization) to maximize the score. The system must be orchestrated on Kubernetes using Pulumi for infrastructure-as-code.

## 2. High-Level Architecture
- **Agents:** Each agent is a microservice (MCP server) running in its own container.
- **Message Queue:** Centralized broker (RabbitMQ/Kafka) for agent communication.
- **Scoring Agent:** Large model agent that evaluates responses and provides reward signals.
- **Small Model Agent:** Learns via GRPO, updates policy based on rewards.
- **Orchestrator/Controller:** Coordinates the workflow and message routing.
- **Kubernetes Cluster:** All components run as pods/services, managed by Pulumi.

## 3. Detailed Steps and Considerations

### 3.1. Define Agent APIs and Message Formats
- Specify REST/gRPC endpoints for inference, scoring, and training.
- Define message schemas (JSON/protobuf) for requests, responses, and rewards.
- Consider versioning and extensibility of message formats.

### 3.2. Implement Small Model Agent
- Build a microservice exposing endpoints for inference and training.
- Integrate GRPO training loop: receive input, generate response, receive reward, update policy.
- Ensure statelessness or use external storage for model checkpoints.

### 3.3. Implement Scoring Agent (Big Model)
- Build a microservice that receives responses, evaluates them, and returns a score/reward.
- Optionally, log responses and scores for analysis.
- Consider batching for efficiency if needed.

### 3.4. Set Up Message Broker
- Choose RabbitMQ or Kafka for message passing.
- Define queues/topics for task, response, and reward messages.
- Ensure reliable delivery and fault tolerance.

### 3.5. Orchestrator/Controller Logic
- Manage the workflow: send tasks, collect responses, route to scoring agent, deliver rewards.
- Optionally, implement as a separate service or as part of the agents.
- Handle retries, failures, and logging.

### 3.6. Containerization
- Write Dockerfiles for each agent and the message broker (if not using managed service).
- Ensure minimal, secure images with required dependencies.

### 3.7. Pulumi Infrastructure-as-Code
- Define Kubernetes resources:
  - Namespaces for isolation
  - Deployments for each agent
  - StatefulSet/Deployment for message broker
  - Services for inter-agent communication
  - ConfigMaps/Secrets for configuration
  - Autoscaling policies
- Automate deployment, updates, and rollbacks.

### 3.8. Scalability and Fault Tolerance
- Use Kubernetes autoscaling for agents and broker.
- Design agents to be stateless or use persistent storage.
- Monitor queue lengths and agent health.

### 3.9. Monitoring and Logging
- Integrate Prometheus/Grafana for metrics.
- Use ELK stack or similar for logs.
- Track training progress, agent performance, and system health.

### 3.10. CI/CD Pipeline
- Automate build, test, and deployment of agent containers.
- Integrate with Pulumi for infrastructure updates.

### 3.11. Extensibility
- Allow easy addition of new agent types or scoring strategies.
- Support swapping models or training algorithms.
- Enable integration with external data sources or UIs.

## 4. Open Questions and Next Steps
- Which message broker to use (RabbitMQ vs Kafka)?
- What ML frameworks for small/big models?
- How to persist and version model checkpoints?
- How to handle agent failures and retries?
- What metrics are most important to monitor?

## 5. Next Actions
- Finalize technology choices (broker, ML frameworks, etc).
- Draft API/message schemas.
- Prototype agent communication locally.
- Write initial Pulumi scripts for cluster setup.
- Iterate and refine based on testing.

## 6. Concrete Implementation Choices (April 19, 2025)

### 6.1. Message Queue
- Use RabbitMQ as the central broker for all agent communication.
- Define queues for: tasks (input to small model agent), responses (output from small model agent), rewards (output from scoring agent).
- Use JSON as the message schema for interoperability.

### 6.2. Agents as MCP Servers
- Each agent (small model agent, scoring agent, orchestrator/controller) runs as an MCP server.
- Each MCP server is containerized with its own Dockerfile.
- Agents subscribe/publish to RabbitMQ queues as needed.

### 6.3. LLM Choice
- Use a small Llama model (e.g., Llama-2-7B or smaller) for the small model agent.
- Containerize the Llama model for both inference and online GRPO training.
- The scoring agent can use a larger LLM or a more advanced evaluation model, also containerized.

### 6.4. Communication and Message Flow
- All communication between agents happens via RabbitMQ queues.
- Standardize message formats (JSON) for tasks, responses, and rewards.
- Document the message schema for each queue.

### 6.5. Containerization
- Each component (RabbitMQ, small model agent, scoring agent, orchestrator) has its own Dockerfile.
- Use docker-compose for local development/testing.
- Ensure all containers expose necessary ports and health checks.

### 6.6. Kubernetes and Pulumi
- Deploy all containers as Kubernetes pods/services.
- Use Pulumi scripts to define deployments, services, config, and autoscaling.
- Ensure RabbitMQ is deployed as a StatefulSet or Deployment with persistent storage.

### 6.7. Next Steps
- Draft message schemas for all queues.
- Write Dockerfiles for each agent and RabbitMQ.
- Prototype local communication using docker-compose.
- Prepare Pulumi scripts for Kubernetes deployment.
- Document all design decisions and update this file as implementation progresses.

## 7. Implementation Metadata and Environment Notes (April 19, 2025)

- User is working in a WSL (Windows Subsystem for Linux) environment.
- Simplicity is prioritized for initial prototyping.
- All containers and scripts should be compatible with Linux/WSL.
- Log all major decisions, environment constraints, and implementation steps in this file.
- Use relative paths and avoid hardcoding OS-specific details.
- Prefer docker-compose for local orchestration before moving to Kubernetes.
- Document any WSL-specific issues or workarounds encountered during development.

## 8. Next Step: Draft Message Schemas
- Define simple JSON message schemas for:
  - Task (input to small model agent)
  - Response (output from small model agent)
  - Reward (output from scoring agent)
- Keep schemas minimal for now, but allow for future extensibility (e.g., add metadata fields).
- Log the draft schemas in this file before implementation.

## 9. Draft Message Schemas (Initial Version)

### 9.1. Task Message (to Small Model Agent)
{
  "task_id": "string",           // Unique identifier for the task
  "input": "string",             // Input prompt or data for the agent
  "metadata": {                   // Optional metadata (extensible)
    "timestamp": "string",
    "source": "string"
  }
}

### 9.2. Response Message (from Small Model Agent)
{
  "task_id": "string",           // Corresponds to the original task
  "response": "string",          // Agent's generated output
  "agent_id": "string",          // Identifier for the responding agent
  "metadata": {                   // Optional metadata
    "timestamp": "string"
  }
}

### 9.3. Reward Message (from Scoring Agent)
{
  "task_id": "string",           // Corresponds to the original task
  "score": "float",              // Reward/score assigned by the scoring agent
  "scoring_agent_id": "string",  // Identifier for the scoring agent
  "metadata": {                   // Optional metadata
    "timestamp": "string",
    "criteria": "string"         // Description of scoring criteria
  }
}

// These schemas are intentionally minimal for initial prototyping and can be extended as needed.

## 10. Plan for Decoupled Training and Adapter Management (April 19, 2025)

### 10.1. Decoupled Trainer Design
- The trainer is a separate service, not part of the main agentic workflow.
- The main workflow (agents, orchestrator, scoring agent) continues to operate and collect data (internal messages, responses, scores).
- All relevant communication and scores are logged to a persistent storage (e.g., database, object storage, or flat files).

### 10.2. Data Collection
- Define a logging mechanism in each agent and the orchestrator to capture:
  - Task input
  - Agent responses
  - Associated scores/rewards
  - Timestamps, agent IDs, and other metadata
- Store this data in a structured format suitable for training (e.g., JSONL, Parquet, or a database table).
- Periodically (or on-demand), the trainer service reads this data for training.

### 10.3. Training Process
- The trainer service loads the collected data and performs GRPO training to produce a new Llama adapter for each submodel (small model agent).
- Training is done offline, decoupled from the main workflow.
- After training, the new adapter is saved and versioned.

### 10.4. Adapter Deployment and A/B Testing
- The new adapter is deployed to a subset of agent instances (A/B test group), while the rest use the current primary adapter (control group).
- The orchestrator tags tasks/responses to track which adapter was used.
- Collect performance metrics (e.g., average score, task success rate) for both groups.
- If the new adapter outperforms the primary adapter, promote it to be the new primary.
- Rollback if the new adapter underperforms.

### 10.5. Versioning and Rollback
- Maintain a registry of adapter versions and their performance metrics.
- Automate promotion/rollback based on A/B test results.
- Log all adapter changes and decisions in this file.

### 10.6. Next Steps
- Define the data schema for logging communication and scores.
- Design the trainer service interface and workflow.
- Plan the adapter deployment and A/B testing mechanism.
- Document all design decisions and update this file as implementation progresses.

## 11. Data Schema for Logging Communication and Scores (Initial Version)

- Store logs as JSONL (one JSON object per line) for simplicity and easy parsing.
- Each log entry contains:
  - task_id: string
  - input: string (task input)
  - response: string (agent output)
  - score: float (reward from scoring agent)
  - agent_id: string (which agent/submodel produced the response)
  - adapter_version: string (which adapter was used)
  - timestamp: string (ISO format)
  - metadata: object (optional, extensible)

Example log entry:
{
  "task_id": "abc123",
  "input": "What is the capital of France?",
  "response": "Paris",
  "score": 0.95,
  "agent_id": "small_model_1",
  "adapter_version": "v1.0.0",
  "timestamp": "2025-04-19T12:34:56Z",
  "metadata": {"source": "test", "criteria": "accuracy"}
}

- All agents and the orchestrator append to a shared log file (e.g., logs/agent_interactions.jsonl).
- The trainer service reads this file for offline GRPO training.

## 12. Trainer Service Interface and Workflow (Initial Version)

- Trainer runs as a separate script/service.
- Reads logs/agent_interactions.jsonl and filters data for each submodel/adapter.
- Performs GRPO training using the collected data.
- Saves new adapter checkpoints (e.g., adapters/small_model_1/v1.0.1/).
- Updates a registry file (adapters/adapter_registry.json) with version and performance info.
- Notifies orchestrator (e.g., via file update or message) when a new adapter is ready for A/B testing.

## 13. Adapter Deployment and A/B Testing (Initial Version)

- Orchestrator assigns a portion of tasks to agents using the new adapter (A/B group), rest use primary adapter (control group).
- Tracks which adapter was used for each response in the log.
- After a test period, compares average scores for A/B and control groups.
- If new adapter outperforms, orchestrator promotes it to primary in adapter_registry.json.
- If not, rolls back to previous adapter.

---

These steps are intentionally simple for initial testing and can be iteratively improved.

---

# [THINKING] 2025-04-19T00:30:00Z
Reviewed latest best practices for agentic microservices architectures, containerization, messaging, logging, model versioning, orchestration, and offline RL trainer design. Sources included recent articles and guides on microservices, agentic workflows, Docker/Kubernetes, RabbitMQ, logging, CI/CD, and model management.

## Reasoning Path
- Searched for best practices for each architectural component and the overall system.
- Synthesized recommendations from multiple sources, focusing on reliability, extensibility, and maintainability.
- Considered alternatives for logging, message schema management, and orchestration patterns.

## Alternatives Considered
- Monolithic vs. microservices: Microservices preferred for modularity and independent scaling.
- Kafka vs. RabbitMQ: RabbitMQ chosen for simplicity and suitability for agentic message patterns.
- Centralized vs. distributed logging: Centralized logging with correlation IDs and consistent schema is best for traceability.
- Manual vs. automated model versioning: Automated versioning and CI/CD pipelines recommended for reliability.

## Final Decision Rationale
Adopt the following best practices:
- Use Docker and Kubernetes for containerization and orchestration.
- Use Pulumi for infrastructure-as-code and CI/CD integration.
- Design durable, persistent RabbitMQ queues with a message schema registry.
- Centralize logging with correlation IDs and consistent formats; avoid logging sensitive data.
- Use semantic versioning and automated pipelines for model/adapters.
- Orchestrator should use graph-based or orchestrator-worker patterns for flexibility and maintainability.
- Trainer service should be decoupled, operate on persistent logs, and automate retraining and adapter promotion/rollback.
- Implement robust monitoring, error handling, and security throughout.

# [CODE-GENERATION] 2025-04-19T01:00:00Z
Added inline references and reasoning for each best practice point in the [THINKING] section, as requested. No content was deleted.

## Inline References and Reasoning for Best Practices
- Use Docker and Kubernetes for containerization and orchestration.
  - Reference: "By containerizing ML models with Docker and orchestrating them with Kubernetes, you can achieve scalability, reliability, and portability." ([javacodegeeks.com](https://www.javacodegeeks.com/2025/03/containerizing-ml-models-with-docker-and-kubernetes.html))
  - Reasoning: Widely adopted in industry for scalable, reproducible deployments; confirmed by multiple guides and case studies.
- Use Pulumi for infrastructure-as-code and CI/CD integration.
  - Reference: "Pulumi Infrastructure as Code (IaC) streamlines Kubernetes cluster configuration, management, and app workload deployments to your clusters." ([pulumi.com](https://www.pulumi.com/kubernetes/))
  - Reasoning: Pulumi enables automation, versioning, and repeatability for cloud infrastructure, as recommended by cloud-native best practices.
- Design durable, persistent RabbitMQ queues with a message schema registry.
  - Reference: "One of the best practices for utilising RabbitMQ in a microservices architecture is to use durable queues and persistent messages." ([thinktoshare.com](https://thinktoshare.com/blogs/reliable-messaging-with-rabbitmq))
  - Reference: "A well-designed message schema registry is vital for maintaining clear contracts between services in an event-driven architecture with RabbitMQ at its core." ([reintech.io](https://reintech.io/blog/designing-message-schema-registry-rabbitmq))
  - Reasoning: Ensures reliable delivery and clear contracts between services, as seen in production microservice deployments.
- Centralize logging with correlation IDs and consistent formats; avoid logging sensitive data.
  - Reference: "Centralizing logging is the first step in working effectively with microservices logs... Use a correlation ID... Keep logs consistent... It's a best practice to ensure that your logs don't include sensitive data like personally identifiable information or passwords." ([groundcover.com](https://www.groundcover.com/microservices-observability/microservices-logging))
  - Reasoning: Centralized, consistent logging is essential for debugging and compliance in distributed systems.
- Use semantic versioning and automated pipelines for model/adapters.
  - Reference: "Use semantic versioning to clearly communicate changes in your models, making it easier to track updates and rollbacks. Implement automated tests for each model version..." ([restack.io](https://www.restack.io/p/version-control-for-ai-answer-machine-learning-model-versioning-best-practices-cat-ai))
  - Reasoning: Enables safe, auditable model updates and rollbacks, as recommended in ML operations literature.
- Orchestrator should use graph-based or orchestrator-worker patterns for flexibility and maintainability.
  - Reference: "An orchestrator agent coordinates multiple worker agents to perform tasks collaboratively, ensuring dependencies are resolved and tasks are completed efficiently." ([github.com/codematrix](https://github.com/codematrix/agentic-ai-design-patterns))
  - Reasoning: Graph-based and orchestrator-worker patterns are proven in multi-agent and workflow systems for extensibility.
- Trainer service should be decoupled, operate on persistent logs, and automate retraining and adapter promotion/rollback.
  - Reference: "Offline reinforcement learning learns exclusively from static datasets of previously collected interactions, making it feasible to extract policies from large and diverse training datasets." ([docs.agilerl.com](https://docs.agilerl.com/en/latest/offline_training/index.html))
  - Reasoning: Decoupling training from inference/serving is a best practice in scalable RL and ML architectures.
- Implement robust monitoring, error handling, and security throughout.
  - Reference: "Implement comprehensive monitoring and logging to track service health and performance. Centralized logging and monitoring solutions are essential for troubleshooting and understanding system behavior." ([mega.com](https://www.mega.com/blog/what-is-microservices-architecture))
  - Reasoning: Monitoring and error handling are critical for reliability and observability in distributed systems.

# [THINKING] 2025-04-19T14:30:00Z
## Reasoning Path
- User pointed out that previous [THINKING] steps were being overwritten instead of appended in agent-thinking.txt.
- Confirmed that the correct approach is to only append new log entries, never delete or overwrite previous content.
- Will now append a new log entry for the STARLING research analysis session, ensuring all previous content is preserved and only new information is added.

## Alternatives Considered
- Could have edited or replaced previous log entries, but this would violate the user's explicit instructions for traceability.

## Final Decision Rationale
- Always append new [THINKING], [DECISION], [CODE-GENERATION], and [METADATA] sections for each session, never delete or overwrite previous logs.

# [CODE-GENERATION] 2025-04-19T14:30:00Z
- Appended a new log entry for the STARLING research analysis session, following the user's instructions for structured, additive logging in agent-thinking.txt.
# [THINKING]
2025-04-19T00:00:00Z
Goal: Synthesize a literature review contextualizing five foundational papers in relation to the agentic workflow and GRPO training project.
Reasoning Path: 
- Read summaries of: LLM Multi-Agent Coordination (arXiv 2023), ProAgent (arXiv 2023), ReAct (ICLR 2023), Reflexion (NeurIPS 2023), STARLING (arXiv 2024).
- Reviewed agent-thinking.txt for project architecture, problem statement, and workflow.
- Identified key themes: multi-agent coordination, proactive/cooperative behavior, reasoning-action loops, self-reflective learning, self-supervised RL.
- Plan: For each paper, summarize core contributions, relate to project design, and synthesize cross-cutting insights and gaps.
Alternatives Considered:
- Only summarizing papers individually (rejected: less useful for project guidance).
- Focusing solely on technical methods (rejected: need to connect to project context).
Final Decision Rationale:
- A contextualized, comparative review will best inform design choices and future research directions for the agentic workflow project.

[DECISION]
2025-04-19T00:00:00Z
Proceed to synthesize a detailed literature review, mapping each paper's contributions, methods, and limitations to the project's architecture and goals. Structure the review for clarity and actionable insights.

[CODE-GENERATION]
2025-04-19T00:00:00Z
Will create 'litrature_review.md' in the project root, following user formatting requirements and including:
- Introduction (project context)
- Individual paper reviews (summary, relevance, limitations)
- Comparative synthesis (cross-paper insights, gaps, recommendations)


 Extend the architecture to:
  1. Add a Feedback Loop: Scoring agent emits both scalar and natural language feedback; small model agent logs and reflects on this before next action.
  2. Hybrid Training: Trainer service supports both self-supervised pretraining (intrinsic objectives) and reward-driven fine-tuning.
  3. Reasoning-Action Logging: Agents log reasoning steps, actions, and reflections for each episode.
  4. Evaluation Benchmarks: Orchestrator manages benchmark tasks and logs results for coordination/proactivity metrics.
- Update architecture diagram to reflect these flows.

# [CODE-GENERATION] 2025-04-19T15:30:00Z
## Implementation Plan
1. **Message Schema Update:**
   - Extend response and reward messages to include `natural_language_feedback` and `reflection` fields.
2. **Small Model Agent:**
   - On receiving feedback, log and reflect before next action.
   - Add a reflection module/class with docstrings, type annotations, and error handling.
3. **Scoring Agent:**
   - Emit both scalar reward and natural language feedback.
   - Add feedback generation logic with error handling and docstrings.
4. **Trainer Service:**
   - Support two training phases: self-supervised (intrinsic) and reward-driven (fine-tuning).
   - Log phase transitions and training metadata.
5. **Orchestrator:**
   - Manage evaluation benchmarks and log coordination/proactivity metrics.
6. **Logging:**
   - All agents log reasoning, actions, feedback, and reflections per episode.
7. **Diagram:**
   - Update/add a Mermaid diagram showing new feedback, reflection, and hybrid training flows.
[METADATA]
2025-04-19T00:00:00Z
Files read: developement_research/llm_multiagent_coordination_arxiv2023.md, proagent_arxiv2023.md, react_iclr2023.md, reflexion_neurips2023.md, starling_arxiv2024.md, agent-thinking.txt
File to create: litrature_review.md
User requirements: prepend/append Copilot tags, detailed docstrings, error handling, agent-thinking.txt logging, project-root file creation.
Session context: Literature review for agentic workflow/GRPO project.
# [METADATA]
agent: Copilot
user: vrishbhanusingh
session: STARLING research analysis log append

# [THINKING] 2025-04-20T00:00:00Z
# Reasoning Path:
# User requested a Mermaid diagram using the chat participant style to visualize the agentic workflow. The chat participant syntax in Mermaid provides a modern, avatar-based sequence diagram, which is suitable for showing the interactions between User, Orchestrator, SmallModelAgent, ScoringAgent, Trainer, and MessageBus. This approach aligns with the project's documentation and visualization standards.
# Alternatives Considered:
# - Use a standard sequence diagram (already present in documentation)
# - Use a flowchart (less suitable for conversational/temporal flow)
# Final Decision Rationale:
# - The chat participant style offers improved clarity and modern documentation aesthetics, making it easier for stakeholders to understand agent interactions at a glance.

# [DECISION] 2025-04-20T00:00:00Z
# Proceed to generate a Mermaid sequence diagram using the chat participant style, covering all major agents and message flows in the agentic workflow. This will be included in documentation and can be referenced in future design discussions.

# [CODE-GENERATION] 2025-04-20T00:00:00Z
# Mermaid diagram code generated for chat participant style agentic workflow visualization.

# [METADATA] 2025-04-20T00:00:00Z
# Author: Copilot
# User: vrishbhanusingh
# Session: Mermaid chat participant diagram generation
# File: agent-thinking.txt
# Context: Agentic workflow documentation, visualization, and traceability.

# [THINKING] 2025-04-20T01:30:00Z
# Reasoning Path:
# The user wants to start small and ensure the environment is ready before implementing agentic features. The repo already contains requirements.txt for each agent, a docker-compose.yml for orchestrated local development, and a logs/ directory for persistent logging. The next step is to verify that Docker, docker-compose, and Python dependencies are installed, and to provide a simple bootstrap command for the user to bring up the environment.
# Alternatives Considered:
# - Begin with code changes for agent features (premature if environment is not ready)
# - Set up Kubernetes/Pulumi now (not needed for initial local development)
# Final Decision Rationale:
# - Start with local Docker Compose setup for rapid iteration and debugging. Kubernetes and cloud deployment can follow after local validation.

# [DECISION] 2025-04-20T01:30:00Z
# Proceed to document and recommend the environment bootstrap steps for local development using Docker Compose, and verify Python dependencies for each agent.

# [CODE-GENERATION] 2025-04-20T01:30:00Z
# To bootstrap the environment, run the following command in the project root:
#
# ## Generated by Copilot
# docker-compose up --build
# ## End of generated code
#
# This will build and start RabbitMQ, small_model_agent, scoring_agent, and orchestrator services. Ensure Docker and docker-compose are installed. To install Python dependencies for local development (outside Docker), run:
#
# ## Generated by Copilot
# pip install -r orchestrator/requirements.txt
# pip install -r small_model_agent/requirements.txt
# pip install -r scoring_agent/requirements.txt
# ## End of generated code
#
# Add any missing dependencies (e.g., torch, transformers) to the respective requirements.txt as you implement ML features.

# [METADATA] 2025-04-20T01:30:00Z
# Author: Copilot
# User: vrishbhanusingh
# Session: Environment bootstrap and verification
# File: agent-thinking.txt
# Context: Initial environment setup for agentic workflow project.