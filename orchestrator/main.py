## Generated by Copilot
"""
Orchestrator CLI for testing agentic workflow communication.
Sends a test task to the small model agent, waits for response and reward, and prints results.
"""
import argparse
import json
import os
import sys
import time
import uuid
from typing import Any, Dict, NoReturn
import pika
import threading
from fastapi import FastAPI, HTTPException
import uvicorn

TASK_QUEUE = 'task_queue'
RESPONSE_QUEUE = 'response_queue'
REWARD_QUEUE = 'reward_queue'

RABBITMQ_HOST = os.environ.get('RABBITMQ_HOST', 'rabbitmq')  # Use 'rabbitmq' for Docker
RABBITMQ_USER = os.environ.get('RABBITMQ_USER', 'user')
RABBITMQ_PASS = os.environ.get('RABBITMQ_PASS', 'password')
LOG_FILE = os.path.join(os.path.dirname(os.path.dirname(__file__)), "logs", "agent_interactions.jsonl")


def log_event(event: Dict[str, Any]) -> None:
    """
    Append a structured event to the orchestrator log file as JSONL.
    Log schema (one JSON object per line):
        {
            "event": str,  # e.g., 'task_sent', 'response_received', 'reward_received', 'error'
            "timestamp": str,  # ISO8601 UTC
            "task_id": str,
            "input": str,  # Only for 'task_sent'
            "response": str,  # Only for 'response_received'
            "reward": float,  # Only for 'reward_received'
            "error": str,  # Only for 'error'
            "source": str,  # 'persistent_orchestrator', 'cli', etc.
            "metadata": dict  # Optional, extensible
        }
    Args:
        event: The event dictionary to log.
    Raises:
        OSError: If the log file cannot be written.
    Usage:
        log_event({"event": "task_sent", ...})
    """
    try:
        os.makedirs(os.path.dirname(LOG_FILE), exist_ok=True)
        with open(LOG_FILE, "a") as f:
            f.write(json.dumps(event) + "\n")
    except Exception as e:
        print(f"[Orchestrator][LOGGING ERROR] {e}", file=sys.stderr)


def send_task_and_get_result(task_input: str, timeout: float = 10.0) -> None:
    """
    Send a test task to the small model agent and print the response and reward.
    Args:
        task_input: The input string for the task.
        timeout: How long to wait for responses (seconds).
    Raises:
        RuntimeError: If no response or reward is received in time.
    """
    credentials = pika.PlainCredentials(RABBITMQ_USER, RABBITMQ_PASS)
    connection = pika.BlockingConnection(pika.ConnectionParameters(host=RABBITMQ_HOST, credentials=credentials))
    channel = connection.channel()
    # Ensure queues exist
    channel.queue_declare(queue=TASK_QUEUE, durable=True)
    channel.queue_declare(queue=RESPONSE_QUEUE, durable=True)
    channel.queue_declare(queue=REWARD_QUEUE, durable=True)

    task_id = f"test-{int(time.time())}"
    task_msg = {
        "task_id": task_id,
        "input": task_input,
        "metadata": {"timestamp": time.strftime('%Y-%m-%dT%H:%M:%SZ'), "source": "cli"}
    }
    channel.basic_publish(
        exchange='', routing_key=TASK_QUEUE, body=json.dumps(task_msg),
        properties=pika.BasicProperties(delivery_mode=2)
    )
    print(f"[Orchestrator] Sent task: {task_msg}")
    log_event({
        "event": "task_sent",
        "task_id": task_id,
        "input": task_input,
        "timestamp": time.strftime('%Y-%m-%dT%H:%M:%SZ'),
        "source": "cli",
        "metadata": task_msg.get("metadata", {})
    })

    response = None
    reward = None
    start = time.time()
    # Wait for response
    while time.time() - start < timeout:
        method, props, body = channel.basic_get(RESPONSE_QUEUE, auto_ack=True)
        if body:
            msg = json.loads(body)
            if msg.get('task_id') == task_id:
                response = msg
                print(f"[Orchestrator] Got response: {response}")
                break
        time.sleep(0.2)
    if not response:
        log_event({
            "event": "error",
            "type": "no_response",
            "task_id": task_id,
            "timestamp": time.strftime('%Y-%m-%dT%H:%M:%SZ'),
            "source": "cli"
        })
        raise RuntimeError("No response received from small model agent.")
    log_event({
        "event": "response_received",
        "task_id": task_id,
        "response": response.get("response", str(response)),
        "timestamp": time.strftime('%Y-%m-%dT%H:%M:%SZ'),
        "source": "cli",
        "metadata": response.get("metadata", {})
    })

    # Wait for reward
    start = time.time()
    while time.time() - start < timeout:
        method, props, body = channel.basic_get(REWARD_QUEUE, auto_ack=True)
        if body:
            msg = json.loads(body)
            if msg.get('task_id') == task_id:
                reward = msg
                print(f"[Orchestrator] Got reward: {reward}")
                break
        time.sleep(0.2)
    if not reward:
        log_event({
            "event": "error",
            "type": "no_reward",
            "task_id": task_id,
            "timestamp": time.strftime('%Y-%m-%dT%H:%M:%SZ'),
            "source": "cli"
        })
        raise RuntimeError("No reward received from scoring agent.")
    log_event({
        "event": "reward_received",
        "task_id": task_id,
        "reward": reward.get("score", reward),
        "timestamp": time.strftime('%Y-%m-%dT%H:%M:%SZ'),
        "source": "cli",
        "metadata": reward.get("metadata", {})
    })
    print("[Orchestrator] Test complete.")
    connection.close()


def persistent_task_sender() -> NoReturn:
    """
    Continuously sends a dummy task message to the small model agent every 10 seconds.
    Also consumes and prints any messages from RESPONSE_QUEUE and REWARD_QUEUE.
    Handles connection errors and retries indefinitely.
    Each message includes a unique task_id and ISO timestamp.
    Raises:
        Never returns; logs and recovers from all exceptions.
    Usage:
        Called as the main entrypoint for persistent orchestrator mode.
    """
    credentials: pika.PlainCredentials = pika.PlainCredentials(RABBITMQ_USER, RABBITMQ_PASS)
    while True:
        try:
            connection: pika.BlockingConnection = pika.BlockingConnection(
                pika.ConnectionParameters(host=RABBITMQ_HOST, credentials=credentials)
            )
            channel = connection.channel()
            channel.queue_declare(queue=TASK_QUEUE, durable=True)
            channel.queue_declare(queue=RESPONSE_QUEUE, durable=True)
            channel.queue_declare(queue=REWARD_QUEUE, durable=True)
            last_task_time: float = 0.0
            while True:
                now: float = time.time()
                # Send a new task every 10 seconds
                if now - last_task_time >= 10.0:
                    task_id: str = str(uuid.uuid4())
                    task_msg: dict[str, object] = {
                        "task_id": task_id,
                        "input": "Dummy message from orchestrator",
                        "metadata": {"timestamp": time.strftime('%Y-%m-%dT%H:%M:%SZ'), "source": "persistent_orchestrator"}
                    }
                    channel.basic_publish(
                        exchange='', routing_key=TASK_QUEUE, body=json.dumps(task_msg),
                        properties=pika.BasicProperties(delivery_mode=2)
                    )
                    print(f"[Orchestrator] Sent dummy task: {task_msg}")
                    log_event({
                        "event": "task_sent",
                        "task_id": task_id,
                        "input": task_msg["input"],
                        "timestamp": time.strftime('%Y-%m-%dT%H:%M:%SZ'),
                        "source": "persistent_orchestrator",
                        "metadata": task_msg.get("metadata", {})
                    })
                    assert isinstance(task_msg["task_id"], str) and task_msg["task_id"], "task_id must be a non-empty string"
                    last_task_time = now
                # Non-blocking consume from RESPONSE_QUEUE
                method, props, body = channel.basic_get(RESPONSE_QUEUE, auto_ack=True)
                if body:
                    try:
                        msg = json.loads(body)
                        log_event({
                            "event": "response_received",
                            "task_id": msg.get("task_id"),
                            "response": msg.get("response", str(msg)),
                            "timestamp": time.strftime('%Y-%m-%dT%H:%M:%SZ'),
                            "source": "persistent_orchestrator",
                            "metadata": msg.get("metadata", {})
                        })
                    except Exception as e:
                        log_event({
                            "event": "error",
                            "type": "decode_response",
                            "error": str(e),
                            "timestamp": time.strftime('%Y-%m-%dT%H:%M:%SZ'),
                            "source": "persistent_orchestrator"
                        })
                # Non-blocking consume from REWARD_QUEUE
                method, props, body = channel.basic_get(REWARD_QUEUE, auto_ack=True)
                if body:
                    try:
                        msg = json.loads(body)
                        log_event({
                            "event": "reward_received",
                            "task_id": msg.get("task_id"),
                            "reward": msg.get("score", msg),
                            "timestamp": time.strftime('%Y-%m-%dT%H:%M:%SZ'),
                            "source": "persistent_orchestrator",
                            "metadata": msg.get("metadata", {})
                        })
                    except Exception as e:
                        log_event({
                            "event": "error",
                            "type": "decode_reward",
                            "error": str(e),
                            "timestamp": time.strftime('%Y-%m-%dT%H:%M:%SZ'),
                            "source": "persistent_orchestrator"
                        })
                time.sleep(0.5)
        except pika.exceptions.AMQPConnectionError as e:
            print(f"[Orchestrator][ERROR] RabbitMQ connection error: {e}. Retrying in 5 seconds...")
            log_event({
                "event": "error",
                "type": "rabbitmq_connection",
                "error": str(e),
                "timestamp": time.strftime('%Y-%m-%dT%H:%M:%SZ')
            })
            time.sleep(5)
        except Exception as e:
            print(f"[Orchestrator][ERROR] Unexpected error: {e}. Retrying in 5 seconds...")
            log_event({
                "event": "error",
                "type": "unexpected",
                "error": str(e),
                "timestamp": time.strftime('%Y-%m-%dT%H:%M:%SZ')
            })
            time.sleep(5)


def main() -> None:
    """
    CLI entry point for orchestrator testing or persistent mode.
    """
    parser = argparse.ArgumentParser(description="Orchestrator CLI for agentic workflow test.")
    parser.add_argument('--test', action='store_true', help='Send a test task and print results')
    parser.add_argument('--input', type=str, default='What is the capital of France?', help='Task input string')
    parser.add_argument('--persistent', action='store_true', help='Run orchestrator in persistent mode (send dummy tasks every 10s)')
    args = parser.parse_args()
    if args.test:
        try:
            send_task_and_get_result(args.input)
        except Exception as e:
            print(f"[Orchestrator] Error: {e}", file=sys.stderr)
            sys.exit(1)
    elif args.persistent:
        persistent_task_sender()
    else:
        parser.print_help()


app = FastAPI(title="Orchestrator MCP Server")

@app.get("/health")
def health() -> Dict[str, str]:
    """
    Health check endpoint for the MCP server.
    Returns:
        A dict indicating server health.
    """
    return {"status": "ok"}

@app.get("/status")
def status() -> Dict[str, Any]:
    """
    Status endpoint for the MCP server.
    Returns:
        A dict with orchestrator status.
    """
    return {"status": "running"}

@app.get("/metrics")
def metrics() -> Dict[str, Any]:
    """
    Metrics endpoint for the MCP server.
    Returns:
        A dict with basic metrics (placeholder).
    """
    return {"tasks_sent": 0, "responses_received": 0, "rewards_received": 0}


def start_orchestrator_cli() -> None:
    """
    Starts the orchestrator CLI in a background thread.
    """
    try:
        main()
    except Exception as e:
        print(f"Orchestrator CLI crashed: {e}")


if __name__ == "__main__":
    # Start orchestrator CLI in a background thread
    orchestrator_thread = threading.Thread(target=start_orchestrator_cli, daemon=True)
    orchestrator_thread.start()
    # Start FastAPI server
    uvicorn.run(app, host="0.0.0.0", port=8000)
## End of generated code
